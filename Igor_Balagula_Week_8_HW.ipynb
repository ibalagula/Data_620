{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#1. Choose a corpus of interest.\n",
    "# inaugural address corpus\n",
    "from __future__ import division\n",
    "import nltk\n",
    "from nltk.book import *\n",
    "from nltk.corpus import inaugural\n",
    "text = inaugural.words()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#2. How many total unique words are in the corpus? (Please feel free to define unique words in any interesting, defensible way).\n",
    "# we will define unique words as any dictionary word independent of case\n",
    "unique_num_words = len(set([word.lower() for word in text if word.isalpha()]))\n",
    "print \"Number of unique words in Inaugural corpus: \"+str(unique_num_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#3. Taking the most common words, how many unique words represent half of the total words in the corpus?\n",
    "\n",
    "total_num_words = len([word.lower() for word in text if word.isalpha()])\n",
    "print \"The total number of words in the corpus: \"+ str(total_num_words)\n",
    "fdist=FreqDist(text)\n",
    "\n",
    "sum =0\n",
    "i=0\n",
    "for w in fdist.most_common():\n",
    "    print w[0] +' = ' + str(w[1])\n",
    "    sum=sum+w[1]\n",
    "    i=i+1\n",
    "    if sum >= total_num_words/2:\n",
    "        print 'Number of unique words that represent half of the total words in the corpus: ' + str(i)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#4. Identify the 200 highest frequency words in this corpus.\n",
    "\n",
    "vocabulary1=fdist.keys()\n",
    "vocabulary1[:200]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#5. Create a graph that shows the relative frequency of these 200 words.\n",
    "fdist.plot(200, cumulative=True)\n",
    "fdist.plot(200)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#6. Does the observed relative frequency of these words follow Zipf law? Explain.\n",
    "fdist.most_common(200)\n",
    "\n",
    "# We can see that the relative frequency follows Zipf law in general but the quantities are nt exactly\n",
    "# inversly proportional. For example, frequency of word #50 \"they\" is 341 and frequency of word #150 \"most\" is 166.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#7. In what ways do you think the frequency of the words in this corpus differ from “all words in all corpora.”\n",
    "\n",
    "# Because of the nature of this corpus (inaugural speeches) some words with high frequency are not as frequent in all corpora. For example, word\n",
    "# Government appears 591 times (#119 in the frequency distribution), word \"Constitution\" appears 196 times (#136 in the frequency distribution),\n",
    "# word \"America\" appears 192 times (#140 in the frequency distribution)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
